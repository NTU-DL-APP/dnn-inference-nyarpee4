import tensorflow as tf
import numpy as np
import json
import os

# === ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ ===
model_dir = './model'
os.makedirs(model_dir, exist_ok=True)

# === ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ===
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()
x_train = x_train.astype(np.float32) / 255.0
x_test = x_test.astype(np.float32) / 255.0

# Flatten: (28, 28) â†’ (784)
x_train = x_train.reshape((-1, 784))
x_test = x_test.reshape((-1, 784))

# === ãƒ¢ãƒ‡ãƒ«ã®å®šç¾© ===
model = tf.keras.models.Sequential([
    tf.keras.layers.Input(shape=(784,)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# === ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ ===
print("ğŸš€ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­...")
model.fit(x_train, y_train, epochs=50, batch_size=64, validation_split=0.1)

# === ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ ===
print("ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ä¸­...")
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"âœ… ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_acc * 100:.2f}%")

# === æ•°ä»¶ã®äºˆæ¸¬å‡ºåŠ› ===
predictions = model.predict(x_test[:5])
predicted_labels = np.argmax(predictions, axis=1)

print("\nğŸ” ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬çµæœ:")
for i in range(5):
    print(f"ç”»åƒ{i+1}: äºˆæ¸¬ = {predicted_labels[i]}, å®Ÿéš› = {y_test[i]}")

# === ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ ===
model.save(os.path.join(model_dir, 'fashion_mnist.h5'))

# === ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆJSONï¼‰ã‚’ä¿å­˜ ===
model_json = model.to_json()
with open(os.path.join(model_dir, 'fashion_mnist.json'), 'w') as f:
    f.write(model_json)

# === é‡ã¿ï¼ˆNumPyå½¢å¼ï¼‰ã‚’ä¿å­˜ ===
weights_dict = {}
for layer in model.layers:
    weights = layer.get_weights()
    if weights:
        weights_dict[f"{layer.name}.weight"] = weights[0]  # W
        weights_dict[f"{layer.name}.bias"] = weights[1]    # b

np.savez(os.path.join(model_dir, 'fashion_mnist.npz'), **weights_dict)

print("\nâœ… ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»è©•ä¾¡ãƒ»ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
